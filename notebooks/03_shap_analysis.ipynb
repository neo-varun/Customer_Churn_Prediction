{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1774ef5d",
   "metadata": {},
   "source": [
    "# SHAP Analysis for Model Interpretability\n",
    "This notebook demonstrates how to use SHAP (SHapley Additive exPlanations) to interpret the predictions of machine learning models for customer churn. We will visualize feature importance and explain individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddfbe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df2a4e",
   "metadata": {},
   "source": [
    "## 1. Load Data and Model\n",
    "We will use the processed data and a trained XGBoost model for SHAP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06499cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "processed = pd.read_csv('../data/processed/processed.csv')\n",
    "X = processed.drop('Churn', axis=1)\n",
    "y = processed['Churn']\n",
    "\n",
    "# Load trained XGBoost model\n",
    "with open('../models/xgboost.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1414f",
   "metadata": {},
   "source": [
    "## 2. SHAP Explainer Setup\n",
    "Create a SHAP explainer for the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d819b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP explainer\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa3c81",
   "metadata": {},
   "source": [
    "## 3. Global Feature Importance\n",
    "Visualize which features are most important for the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary plot (global feature importance)\n",
    "shap.summary_plot(shap_values, X, plot_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92572106",
   "metadata": {},
   "source": [
    "## 4. SHAP Summary Plot (Distribution)\n",
    "See how each feature impacts the model output across all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee87c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary plot (distribution)\n",
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14acef4",
   "metadata": {},
   "source": [
    "## 5. Explain Individual Predictions\n",
    "Visualize SHAP values for a single prediction to understand why the model made a specific decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a single prediction (e.g., first sample)\n",
    "sample_idx = 0\n",
    "shap.plots.waterfall(shap_values[sample_idx], max_display=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a2e70",
   "metadata": {},
   "source": [
    "## 6. Insights from SHAP Analysis\n",
    "- The summary bar plot shows the most influential features for churn prediction.\n",
    "- The distribution plot reveals how feature values affect the likelihood of churn.\n",
    "- Waterfall plots for individual samples help explain specific model decisions, increasing trust and transparency.\n",
    "- Use these insights to refine features, communicate results, and support business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2b940",
   "metadata": {},
   "source": [
    "## 7. SHAP for Other Models\n",
    "SHAP can be used to interpret other models such as Random Forest and Logistic Regression. Below, we demonstrate SHAP analysis for these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Random Forest and Logistic Regression models\n",
    "with open('../models/random_forest.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)\n",
    "with open('../models/logistic_regression.pkl', 'rb') as f:\n",
    "    lr_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5325817a",
   "metadata": {},
   "source": [
    "### SHAP for Random Forest\n",
    "We use TreeExplainer for Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP for Random Forest\n",
    "rf_explainer = shap.TreeExplainer(rf_model)\n",
    "rf_shap_values = rf_explainer.shap_values(X)\n",
    "# Handle both list and array outputs for binary classification\n",
    "if isinstance(rf_shap_values, list):\n",
    "    shap.summary_plot(rf_shap_values[1], X, plot_type='bar')\n",
    "    shap.summary_plot(rf_shap_values[1], X)\n",
    "else:\n",
    "    shap.summary_plot(rf_shap_values, X, plot_type='bar')\n",
    "    shap.summary_plot(rf_shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4fbcf",
   "metadata": {},
   "source": [
    "### SHAP for Logistic Regression\n",
    "We use Explainer for Logistic Regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5aec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP for Logistic Regression\n",
    "lr_explainer = shap.Explainer(lr_model, X)\n",
    "lr_shap_values = lr_explainer(X)\n",
    "shap.summary_plot(lr_shap_values, X, plot_type='bar')\n",
    "shap.summary_plot(lr_shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae55fa",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- TreeExplainer is efficient for tree-based models (Random Forest, XGBoost).\n",
    "- Explainer is suitable for Logistic Regression.\n",
    "- KernelExplainer can be used for any model but is slower.\n",
    "- SHAP provides consistent interpretability across different model types."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
