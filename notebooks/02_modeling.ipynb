{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44aa47c",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "This notebook covers the process of training, tuning, and evaluating machine learning models for customer churn prediction. We will use the processed data and compare multiple algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63d48c",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data\n",
    "We will use the processed dataset generated after feature engineering and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95898bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "processed = pd.read_csv('../data/processed/processed.csv')\n",
    "X = processed.drop('Churn', axis=1)\n",
    "y = processed['Churn']\n",
    "print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b309470",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split\n",
    "Split the data into training and test sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6176d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd84cfe",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "We will train Logistic Regression, Random Forest, and XGBoost models. Hyperparameter tuning is performed using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92eb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models (assumes models are already trained and saved)\n",
    "with open('../models/logistic_regression.pkl', 'rb') as f:\n",
    "    lr_model = pickle.load(f)\n",
    "with open('../models/random_forest.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)\n",
    "with open('../models/xgboost.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34731b1",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "Evaluate each model on the test set and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc644ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    if y_proba is not None:\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f'ROC AUC: {auc:.3f}')\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "print('Logistic Regression:')\n",
    "evaluate_model(lr_model, X_test, y_test)\n",
    "print('Random Forest:')\n",
    "evaluate_model(rf_model, X_test, y_test)\n",
    "print('XGBoost:')\n",
    "evaluate_model(xgb_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4714e",
   "metadata": {},
   "source": [
    "## 5. Model Comparison and Insights\n",
    "Summarize the results and provide insights on which model performed best and why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03bf25c",
   "metadata": {},
   "source": [
    "- Logistic Regression provides a good baseline and is interpretable.\n",
    "- Random Forest and XGBoost often achieve higher accuracy and ROC AUC, especially with tuned hyperparameters.\n",
    "- ROC curves and confusion matrices help visualize the trade-offs between models.\n",
    "- Consider business context and interpretability when selecting the final model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
